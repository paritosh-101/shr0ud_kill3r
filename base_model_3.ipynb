{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from skimage.metrics import structural_similarity\n",
    "from skimage.metrics import normalized_root_mse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCRIMINATOR**\n",
    "\n",
    "Patch-GAN: To generate an error with source and outcome as inputs, so that it is conditionally dependent on what it _should_ look like given a certain input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the discriminator model\n",
    "def define_discriminator(image_shape):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# source image input\n",
    "\tin_src_image = Input(shape=image_shape)\n",
    "\t# target image input\n",
    "\tin_target_image = Input(shape=image_shape)\n",
    "\t# concatenate images channel-wise\n",
    "\tmerged = Concatenate()([in_src_image, in_target_image])\n",
    "\t# C64\n",
    "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C128\n",
    "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C256\n",
    "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C512\n",
    "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "# \tsecond last output layer\n",
    "\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# patch output\n",
    "\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\tpatch_out = Activation('sigmoid')(d)\n",
    "\t# define model\n",
    "\tmodel = Model([in_src_image, in_target_image], patch_out)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256, 256, 6)  0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 64) 6208        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 128, 128, 64) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 128)  131200      leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 256)  524544      leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 512)  2097664     leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 512)  2048        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 512)  4194816     leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 512)  2048        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 1)    8193        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16, 16, 1)    0           conv2d_5[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,968,257\n",
      "Trainable params: 6,965,441\n",
      "Non-trainable params: 2,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = define_discriminator((256,256,3))\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERATOR**\n",
    "\n",
    "Define a U-Net encoder and decoder block functions. The skip connections are to reinforce the reconstruction of the coloured image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an encoder block\n",
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# add downsampling layer\n",
    "\tg = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "\t# conditionally add batch normalization\n",
    "\tif batchnorm:\n",
    "\t\tg = BatchNormalization()(g, training=True)\n",
    "\t# leaky relu activation\n",
    "\tg = LeakyReLU(alpha=0.2)(g)\n",
    "\treturn g\n",
    "\n",
    "# define a decoder block\n",
    "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# add upsampling layer\n",
    "\tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "\t# add batch normalization\n",
    "\tg = BatchNormalization()(g, training=True)\n",
    "\t# conditionally add dropout\n",
    "\tif dropout:\n",
    "\t\tg = Dropout(0.5)(g, training=True)\n",
    "\t# merge with skip connection\n",
    "\tg = Concatenate()([g, skip_in])\n",
    "\t# relu activation\n",
    "\tg = Activation('relu')(g)\n",
    "\treturn g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(image_shape=(256,256,3)):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# image input\n",
    "\tin_image = Input(shape=image_shape)\n",
    "\t# encoder model\n",
    "\te1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
    "\te2 = define_encoder_block(e1, 128)\n",
    "\te3 = define_encoder_block(e2, 256)\n",
    "\te4 = define_encoder_block(e3, 512)\n",
    "\te5 = define_encoder_block(e4, 512)\n",
    "\te6 = define_encoder_block(e5, 1024)\n",
    "\te7 = define_encoder_block(e6, 1024)\n",
    "\t# bottleneck, no batch norm and relu\n",
    "\tb = Conv2D(1024, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n",
    "\tb = Activation('relu')(b)\n",
    "\t# decoder model\n",
    "\td1 = decoder_block(b, e7, 1024)\n",
    "\td2 = decoder_block(d1, e6, 1024)\n",
    "\td3 = decoder_block(d2, e5, 512)\n",
    "\td4 = decoder_block(d3, e4, 512, dropout=False)\n",
    "\td5 = decoder_block(d4, e3, 256, dropout=False)\n",
    "\td6 = decoder_block(d5, e2, 128, dropout=False)\n",
    "\td7 = decoder_block(d6, e1, 64, dropout=False)\n",
    "\t# output\n",
    "\tg = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
    "\tout_image = Activation('tanh')(g)\n",
    "\t# define model\n",
    "\tmodel = Model(in_image, out_image)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 64) 3136        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 128, 128, 64) 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 128)  131200      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 256)  524544      leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 512)  2097664     leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 512)    4194816     leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 512)    2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 8, 8, 512)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 4, 4, 1024)   8389632     leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 1024)   4096        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 4, 4, 1024)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 2, 2, 1024)   16778240    leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 2, 2, 1024)   4096        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 2, 2, 1024)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 1, 1, 1024)   16778240    leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 1, 1024)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 2, 2, 1024)   16778240    activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2, 2, 1024)   4096        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2, 2, 1024)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 2, 2048)   0           dropout[0][0]                    \n",
      "                                                                 leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2, 2, 2048)   0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 4, 4, 1024)   33555456    activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 4, 1024)   4096        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4, 4, 1024)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4, 4, 2048)   0           dropout_1[0][0]                  \n",
      "                                                                 leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 4, 4, 2048)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 8, 8, 512)    16777728    activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 512)    2048        conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8, 8, 512)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 1024)   0           dropout_2[0][0]                  \n",
      "                                                                 leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 8, 8, 1024)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 16, 16, 512)  8389120     activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 512)  2048        conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 1024) 0           batch_normalization_13[0][0]     \n",
      "                                                                 leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 1024) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 32, 32, 256)  4194560     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 256)  1024        conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 512)  0           batch_normalization_14[0][0]     \n",
      "                                                                 leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 512)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 128)  1048704     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 128)  512         conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 256)  0           batch_normalization_15[0][0]     \n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 128, 128, 64) 262208      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 64) 256         conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 128, 128, 128 0           batch_normalization_16[0][0]     \n",
      "                                                                 leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 128, 128, 128 0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 256, 256, 3)  6147        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 256, 256, 3)  0           conv2d_transpose_7[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 129,937,539\n",
      "Trainable params: 129,923,587\n",
      "Non-trainable params: 13,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = define_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GAN**\n",
    "\n",
    "Stacking the generator and discriminator to build the actual GAN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model, image_shape):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\td_model.trainable = False\n",
    "\t# define the source image\n",
    "\tin_src = Input(shape=image_shape)\n",
    "\t# connect the source image to the generator input\n",
    "\tgen_out = g_model(in_src)\n",
    "\t# connect the source input and generator output to the discriminator input\n",
    "\tdis_out = d_model([in_src, gen_out])\n",
    "\t# src image as input, generated image and classification output\n",
    "\tmodel = Model(in_src, [dis_out, gen_out])\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 256, 256, 3)  129937539   input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 16, 16, 1)    6968257     input_4[0][0]                    \n",
      "                                                                 model_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 136,905,796\n",
      "Trainable params: 129,923,587\n",
      "Non-trainable params: 6,982,209\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan = define_gan(generator, discriminator, (256,256,3))\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA HANDLING**\n",
    "\n",
    "We need to load and generate real source (SAR) and target (RGB) images from our dataset. Due to the size, we cannot load it entirely into memory and will have to load the images on demand.\n",
    "\n",
    "The images have to be generalized over four seasons and different geographic locations. Therefore, we build a function to randomly select a season and then randomly select an SAR image and its corresponding optical image pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def get_images(batch_size):\n",
    "    \n",
    "#     base_path = 'munich/'\n",
    "    \n",
    "#     #select season\n",
    "#     files = listdir(base_path)\n",
    "# #     print(files)\n",
    "#     files_len = len(files)\n",
    "# #     print(files_len)\n",
    "#     rint1 = np.random.randint(0, files_len)\n",
    "# #     print(rint1)\n",
    "#     lvl1 = files[rint1]\n",
    "# #     print(lvl1)\n",
    "    \n",
    "#     #select SAR image folder\n",
    "#     files = listdir(base_path + lvl1 + '/s1/')\n",
    "#     files_len = len(files)\n",
    "# #     print(files_len)\n",
    "#     rint2 = np.random.randint(0, files_len)\n",
    "# #     print(rint2)\n",
    "#     lvl2 = files[rint2]\n",
    "# #     print(lvl2)\n",
    "    \n",
    "#     #select SAR image\n",
    "#     s1_path = base_path + lvl1 + '/s1/' + lvl2 + '/'\n",
    "#     files = listdir(s1_path)\n",
    "#     files_len = len(files)\n",
    "# #     print(files_len)\n",
    "#     rint3 = np.random.randint(0, files_len, batch_size)\n",
    "# #     print(rint3)\n",
    "#     files_arr = np.array(files)\n",
    "#     lvl3 = files_arr[rint3]\n",
    "# #     print(lvl3)\n",
    "    \n",
    "#     #select RGB image\n",
    "#     temp2 = lvl2.replace('s1', 's2')\n",
    "#     lvl3_opt = lvl3.tolist()\n",
    "#     temp3 = [sub.replace('_s1_', '_s2_') for sub in lvl3_opt]\n",
    "# #     print(temp2)\n",
    "# #     print(temp3)\n",
    "#     s2_path = base_path + lvl1 + '/s2/' + temp2 + '/'\n",
    "# #     print(s2_path)\n",
    "    \n",
    "#     #load images\n",
    "#     img_sar=[]\n",
    "#     img_opt=[]\n",
    "#     for i in range(batch_size):\n",
    "#         img = load_img(s1_path + lvl3[i])\n",
    "#         img = img_to_array(img)\n",
    "#         img_sar.append(img)\n",
    "#         img = load_img(s2_path + temp3[i])\n",
    "#         img = img_to_array(img)\n",
    "#         img_opt.append(img)\n",
    "        \n",
    "#     img_sar = np.array(img_sar)\n",
    "#     img_opt = np.array(img_opt)\n",
    "#     img_sar = (img_sar - 127.5) / 127.5\n",
    "#     img_opt = (img_opt - 127.5) / 127.5\n",
    "    \n",
    "#     return img_sar, img_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def shuff():\n",
    "    \n",
    "    #select SAR image\n",
    "    s1_path = 'temp/train/s1/'\n",
    "    files = listdir(s1_path)\n",
    "    random.shuffle(files)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24456\n"
     ]
    }
   ],
   "source": [
    "files = shuff()\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper satellite run\n",
    "import numpy as np\n",
    "\n",
    "def get_images(batch_size, files, i):\n",
    "    \n",
    "#     print(\"get image\",i)\n",
    "    sar_img_name = []\n",
    "    opt_img_name = []\n",
    "    \n",
    "#     index = i\n",
    "    for k in range(batch_size):\n",
    "        sar_img_name.append(files[i])\n",
    "        i=i+1\n",
    "        \n",
    "#     print(sar_img_name)\n",
    "    \n",
    "    img_sar=[]\n",
    "    img_opt=[]\n",
    "    \n",
    "    s1_path = 'temp/train/s1/'\n",
    "    for k in range(batch_size):\n",
    "        img = load_img(s1_path + sar_img_name[k])\n",
    "        img = img_to_array(img)\n",
    "        img_sar.append(img)\n",
    "        \n",
    "#     print(len(img_sar))\n",
    "    \n",
    "    #select RGB image\n",
    "    for k in range(batch_size):\n",
    "        opt_img_name.append(sar_img_name[k].replace('_s1_', '_s2_', 1))\n",
    "        \n",
    "#     print(opt_img_name)\n",
    "#     temp = \"\"\n",
    "#     temp.join(opt_img_name)\n",
    "    \n",
    "    s2_path = 'temp/train/s2/'\n",
    "    for k in range(batch_size):\n",
    "        img = load_img(s2_path + opt_img_name[k])\n",
    "    #     img = load_img(s2_path + temp)\n",
    "        img = img_to_array(img)\n",
    "        img_opt.append(img)\n",
    "        \n",
    "#     print(len(img_opt))\n",
    "    \n",
    "    img_sar = np.array(img_sar)\n",
    "    img_opt = np.array(img_opt)\n",
    "    img_sar = (img_sar - 127.5) / 127.5\n",
    "    img_opt = (img_opt - 127.5) / 127.5\n",
    "    \n",
    "#     print(img_sar.shape)\n",
    "#     print(img_opt.shape)\n",
    "    \n",
    "    return img_sar, img_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = shuff()\n",
    "# sar, opt = get_images(3,files,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # satellite run\n",
    "# import numpy as np\n",
    "\n",
    "# def get_images(batch_size, files):\n",
    "    \n",
    "#     #select SAR image\n",
    "#     s1_path = 'munich/train/s1/'\n",
    "#     files = listdir(s1_path)\n",
    "#     files_len = len(files)\n",
    "# #     print(files_len)\n",
    "#     rint3 = np.random.randint(0, files_len, batch_size)\n",
    "# #     print(rint3)\n",
    "#     files_arr = np.array(files)\n",
    "#     lvl3 = files_arr[rint3]\n",
    "# #     print(lvl3)\n",
    "    \n",
    "#     #select RGB image\n",
    "#     lvl3_opt = lvl3.tolist()\n",
    "#     temp3 = [sub.replace('_s1_', '_s2_') for sub in lvl3_opt]\n",
    "# #     print(temp3)\n",
    "#     s2_path = 'munich/train/s2/'\n",
    "    \n",
    "#     #load images\n",
    "#     img_sar=[]\n",
    "#     img_opt=[]\n",
    "#     for i in range(batch_size):\n",
    "#         img = load_img(s1_path + lvl3[i])\n",
    "#         img = img_to_array(img)\n",
    "#         img_sar.append(img)\n",
    "#         img = load_img(s2_path + temp3[i])\n",
    "#         img = img_to_array(img)\n",
    "#         img_opt.append(img)\n",
    "        \n",
    "#     img_sar = np.array(img_sar)\n",
    "#     img_opt = np.array(img_opt)\n",
    "#     img_sar = (img_sar - 127.5) / 127.5\n",
    "#     img_opt = (img_opt - 127.5) / 127.5\n",
    "    \n",
    "#     return img_sar, img_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dog clean run\n",
    "# import numpy as np\n",
    "\n",
    "# def get_images(batch_size):\n",
    "    \n",
    "#     #select SAR image\n",
    "#     path = 'dog/dog_train/'\n",
    "#     files = listdir(path)\n",
    "#     files_len = len(files)\n",
    "# #     print(files_len)\n",
    "#     rint3 = np.random.randint(0, files_len, batch_size)\n",
    "# #     print(rint3)\n",
    "#     files_arr = np.array(files)\n",
    "#     lvl3 = files_arr[rint3]\n",
    "# #     print(lvl3)\n",
    "    \n",
    "#     #select RGB image\n",
    "#     def rgb2gray(rgb):\n",
    "#         return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "#     img = load_img(path + lvl3[0])\n",
    "#     img = img_to_array(img)\n",
    "#     img = (img - 127.5) / 127.5\n",
    "#     gray = rgb2gray(img)\n",
    "#     gray = np.stack((gray,)*3, axis=-1)\n",
    "# #     plt.imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n",
    "# #     plt.show()\n",
    "    \n",
    "#     #load images\n",
    "#     img_gray=[]\n",
    "#     img_rgb=[]\n",
    "    \n",
    "#     img_gray.append(gray)\n",
    "#     img_rgb.append(img)\n",
    "#     img_gray = np.array(img_gray)\n",
    "#     img_rgb = np.array(img_rgb)\n",
    "    \n",
    "#     return img_gray, img_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dog noisy run\n",
    "# import numpy as np\n",
    "\n",
    "# def get_images(batch_size):\n",
    "    \n",
    "#     #select SAR image\n",
    "#     path = 'dog/dog_train/'\n",
    "#     files = listdir(path)\n",
    "#     files_len = len(files)\n",
    "# #     print(files_len)\n",
    "#     rint3 = np.random.randint(0, files_len, batch_size)\n",
    "# #     print(rint3)\n",
    "#     files_arr = np.array(files)\n",
    "#     lvl3 = files_arr[rint3]\n",
    "# #     print(lvl3)\n",
    "    \n",
    "#     #select RGB image\n",
    "#     def rgb2gray(rgb):\n",
    "#         return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "#     noise = np.random.normal(0, 0.45, (256,256,3))\n",
    "    \n",
    "#     img = load_img(path + lvl3[0])\n",
    "#     img = img_to_array(img)\n",
    "#     img = (img - 127.5) / 127.5\n",
    "#     img2 = img+noise\n",
    "#     gray = rgb2gray(img2)\n",
    "#     gray = np.stack((gray,)*3, axis=-1)\n",
    "# #     plt.imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n",
    "# #     plt.show()\n",
    "    \n",
    "#     #load images\n",
    "#     img_gray=[]\n",
    "#     img_rgb=[]\n",
    "    \n",
    "#     img_gray.append(gray)\n",
    "#     img_rgb.append(img)\n",
    "#     img_gray = np.array(img_gray)\n",
    "#     img_rgb = np.array(img_rgb)\n",
    "    \n",
    "#     return img_gray, img_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src, tar = get_images(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(src[0])\n",
    "# src = (src + 1) / 2\n",
    "# plt.imshow(src[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tar = (tar + 1) / 2\n",
    "# plt.imshow(tar[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(batch_size, patch_shape, files, i):\n",
    "    \n",
    "#     print(\"real sample\",i)\n",
    "    #SAR RGB image pair\n",
    "    src, tar = get_images(batch_size, files, i)\n",
    "    #real labels '1'\n",
    "    y = np.ones((batch_size, patch_shape, patch_shape, 1))\n",
    "    \n",
    "    return [src,tar], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(g_model, batch_size, patch_shape):\n",
    "    \n",
    "    #generated RGB image\n",
    "    X = g_model.predict(batch_size)\n",
    "    #fake labels '0'\n",
    "    y = np.zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, index, d_model, g_model, files, n_samples=1):\n",
    "\t# select a sample of input images\n",
    "    [X_realA, X_realB], _ = generate_real_samples(n_samples, 1, files, index)\n",
    "\t# generate a batch of fake samples\n",
    "    X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
    "\t# scale all pixels from [-1,1] to [0,1]\n",
    "    X_realA = (X_realA + 1) / 2.0\n",
    "    X_realB = (X_realB + 1) / 2.0\n",
    "    X_fakeB = (X_fakeB + 1) / 2.0\n",
    "    \n",
    "    score = structural_similarity(X_fakeB[0], X_realB[0], multichannel=True)\n",
    "#     t = \"SSIM score = {}\"\n",
    "#     w = t.format(score)\n",
    "    ssim_score.append(score)\n",
    "    \n",
    "    score2 = normalized_root_mse(X_realB[0], X_fakeB[0])\n",
    "    rmse_score.append(score2)\n",
    "    \n",
    "\t# plot real source images\n",
    "    plt.figure(figsize=(10.1,3.45))\n",
    "#     plt.text(0, 280, w, fontsize=15)\n",
    "    for i in range(n_samples):\n",
    "#         plt.figure(figsize=(3.2,3.2))\n",
    "#         plt.subplot(1, n_samples, 1 + i)\n",
    "        plt.subplot(131)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_realA[i])\n",
    "\t# plot generated target image\n",
    "    for i in range(n_samples):\n",
    "#         plt.figure(figsize=(3.2,3.2))\n",
    "#         plt.subplot(1, n_samples, 1 + n_samples + i)\n",
    "        plt.subplot(132)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_fakeB[i])\n",
    "\t# plot real target image\n",
    "    for i in range(n_samples):\n",
    "#         plt.figure(figsize=(3.2,3.2))\n",
    "#         plt.subplot(1, n_samples, 1 + n_samples*2 + i)\n",
    "        plt.subplot(133)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_realB[i])\n",
    "\t# save plot to file\n",
    "    filename1 = 'plot_%06d.png' % (step+1)\n",
    "    plt.savefig(filename1)\n",
    "    plt.close()\n",
    "\t# save the generator model\n",
    "    filename2 = 'g_model_%06d.h5' % (step+1)\n",
    "    g_model.save(filename2)\n",
    "    # save discriminator\n",
    "    filename3 = 'd_model_%06d.h5' % (step+1)\n",
    "    d_model.save(filename3)\n",
    "    print('>Saved: %s and %s and %s' % (filename1, filename2, filename3))\n",
    "    print('SSIM = ', score)\n",
    "    print('RMSE = ', score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "def train(d_model, g_model, gan_model, n_images, n_epochs=50, n_batch=5):\n",
    "\t# determine the output square shape of the discriminator\n",
    "    n_patch = d_model.output_shape[1]\n",
    "\t# calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(n_images / n_batch)\n",
    "\t# calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "\t# manually enumerate epochs\n",
    "    j=0\n",
    "    for i in range(n_steps):\n",
    "        # shuffle\n",
    "        if(j==0):\n",
    "            files = shuff()\n",
    "        if((j) % 24456 == 0 or j>24456):\n",
    "            files = shuff()\n",
    "            j=0\n",
    "\t\t# select a batch of real samples\n",
    "        [X_realA, X_realB], y_real = generate_real_samples(n_batch, n_patch, files, j)\n",
    "\t\t# generate a batch of fake samples\n",
    "        X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "\t\t# update discriminator for real samples\n",
    "        d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "        d1_loss.append(d_loss1)\n",
    "\t\t# update discriminator for generated samples\n",
    "        d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "        d2_loss.append(d_loss2)\n",
    "\t\t# update the generator\n",
    "        g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "        gen_loss.append(g_loss)\n",
    "\t\t# summarize performance\n",
    "        if (i+1) % 6113 == 0:\n",
    "            print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "\t\t# summarize model performance\n",
    "# \t\tif (i+1) % (bat_per_epo * 10) == 0:\n",
    "        if (i+1) % 8151 == 0:\n",
    "            summarize_performance(i, j, d_model, g_model, files)\n",
    "            \n",
    "        j=j+n_batch\n",
    "#         print(\"train\",j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-7e84be1421a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mssim_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-328798de2404>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(d_model, g_model, gan_model, n_images, n_epochs, n_batch)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[1;31m# select a batch of real samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mX_realA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_realB\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_real_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_patch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                 \u001b[1;31m# generate a batch of fake samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mX_fakeB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_realA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_patch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-277996c2f76a>\u001b[0m in \u001b[0;36mgenerate_real_samples\u001b[1;34m(batch_size, patch_shape, files, i)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#     print(\"real sample\",i)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#SAR RGB image pair\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m#real labels '1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-36367b680cdb>\u001b[0m in \u001b[0;36mget_images\u001b[1;34m(batch_size, files, i)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#     index = i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0msar_img_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#input shape\n",
    "image_shape = (256, 256, 3)\n",
    "\n",
    "#number of images\n",
    "n_images = 24456\n",
    "\n",
    "ssim_score = []\n",
    "rmse_score = []\n",
    "d1_loss = []\n",
    "d2_loss = []\n",
    "gen_loss = []\n",
    "\n",
    "# define the models\n",
    "d_model = define_discriminator(image_shape)\n",
    "g_model = define_generator(image_shape)\n",
    "# define the composite model\n",
    "gan_model = define_gan(g_model, d_model, image_shape)\n",
    "\n",
    "# train model\n",
    "train(d_model, g_model, gan_model, n_images)\n",
    "\n",
    "plt.plot(ssim_score)\n",
    "plt.ylabel('SSIM')\n",
    "plt.show "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(lulu[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(lulu[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ssim_score[5])\n",
    "# plt.plot(ssim_score)\n",
    "# plt.ylabel('SSIM')\n",
    "# plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
