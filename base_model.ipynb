{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from skimage.metrics import structural_similarity\n",
    "from skimage.metrics import normalized_root_mse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCRIMINATOR**\n",
    "\n",
    "Patch-GAN: To generate an error with source and outcome as inputs, so that it is conditionally dependent on what it _should_ look like given a certain input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the discriminator model\n",
    "def define_discriminator(image_shape):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# source image input\n",
    "\tin_src_image = Input(shape=image_shape)\n",
    "\t# target image input\n",
    "\tin_target_image = Input(shape=image_shape)\n",
    "\t# concatenate images channel-wise\n",
    "\tmerged = Concatenate()([in_src_image, in_target_image])\n",
    "\t# C64\n",
    "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C128\n",
    "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C256\n",
    "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C512\n",
    "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# second last output layer\n",
    "\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# patch output\n",
    "\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\tpatch_out = Activation('sigmoid')(d)\n",
    "\t# define model\n",
    "\tmodel = Model([in_src_image, in_target_image], patch_out)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256, 256, 6)  0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 6208        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 128)  131200      leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 256)  524544      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 512)  2097664     leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 512)  2048        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 512)  4194816     leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 512)  2048        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 1)    8193        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16, 16, 1)    0           conv2d_6[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,968,257\n",
      "Trainable params: 6,965,441\n",
      "Non-trainable params: 2,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = define_discriminator((256,256,3))\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERATOR**\n",
    "\n",
    "Define a U-Net encoder and decoder block functions. The skip connections are to reinforce the reconstruction of the coloured image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an encoder block\n",
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# add downsampling layer\n",
    "\tg = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "\t# conditionally add batch normalization\n",
    "\tif batchnorm:\n",
    "\t\tg = BatchNormalization()(g, training=True)\n",
    "\t# leaky relu activation\n",
    "\tg = LeakyReLU(alpha=0.2)(g)\n",
    "\treturn g\n",
    "\n",
    "# define a decoder block\n",
    "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# add upsampling layer\n",
    "\tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "\t# add batch normalization\n",
    "\tg = BatchNormalization()(g, training=True)\n",
    "\t# conditionally add dropout\n",
    "\tif dropout:\n",
    "\t\tg = Dropout(0.5)(g, training=True)\n",
    "\t# merge with skip connection\n",
    "\tg = Concatenate()([g, skip_in])\n",
    "\t# relu activation\n",
    "\tg = Activation('relu')(g)\n",
    "\treturn g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(image_shape=(256,256,3)):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# image input\n",
    "\tin_image = Input(shape=image_shape)\n",
    "\t# encoder model\n",
    "\te1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
    "\te2 = define_encoder_block(e1, 128)\n",
    "\te3 = define_encoder_block(e2, 256)\n",
    "\te4 = define_encoder_block(e3, 512)\n",
    "\te5 = define_encoder_block(e4, 512)\n",
    "\te6 = define_encoder_block(e5, 512)\n",
    "\te7 = define_encoder_block(e6, 512)\n",
    "\t# bottleneck, no batch norm and relu\n",
    "\tb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n",
    "\tb = Activation('relu')(b)\n",
    "\t# decoder model\n",
    "\td1 = decoder_block(b, e7, 512)\n",
    "\td2 = decoder_block(d1, e6, 512)\n",
    "\td3 = decoder_block(d2, e5, 512)\n",
    "\td4 = decoder_block(d3, e4, 512, dropout=False)\n",
    "\td5 = decoder_block(d4, e3, 256, dropout=False)\n",
    "\td6 = decoder_block(d5, e2, 128, dropout=False)\n",
    "\td7 = decoder_block(d6, e1, 64, dropout=False)\n",
    "\t# output\n",
    "\tg = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
    "\tout_image = Activation('tanh')(g)\n",
    "\t# define model\n",
    "\tmodel = Model(in_image, out_image)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 64) 3136        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 128, 128, 64) 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 128)  131200      leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 128)  512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 256)  524544      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 512)  2097664     leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 512)  2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 512)    4194816     leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 512)    2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 8, 8, 512)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 4, 512)    4194816     leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 4, 512)    2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 4, 4, 512)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 2, 2, 512)    4194816     leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2, 2, 512)    2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 2, 2, 512)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 1, 1, 512)    4194816     leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1, 1, 512)    0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 2, 2, 512)    4194816     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 2, 2, 512)    2048        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2, 2, 512)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2, 2, 1024)   0           dropout_1[0][0]                  \n",
      "                                                                 leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 2, 2, 1024)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 4, 4, 512)    8389120     activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 512)    2048        conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4, 4, 512)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4, 4, 1024)   0           dropout_2[0][0]                  \n",
      "                                                                 leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 4, 4, 1024)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 8, 8, 512)    8389120     activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 512)    2048        conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 8, 8, 512)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8, 8, 1024)   0           dropout_3[0][0]                  \n",
      "                                                                 leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 8, 1024)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 16, 16, 512)  8389120     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 512)  2048        conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 1024) 0           batch_normalization_14[0][0]     \n",
      "                                                                 leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 1024) 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 32, 32, 256)  4194560     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 256)  1024        conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 512)  0           batch_normalization_15[0][0]     \n",
      "                                                                 leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 512)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 64, 64, 128)  1048704     activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 64, 128)  512         conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 256)  0           batch_normalization_16[0][0]     \n",
      "                                                                 leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 256)  0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 128, 128, 64) 262208      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 128, 128, 64) 256         conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 128, 128, 128 0           batch_normalization_17[0][0]     \n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 128, 128, 128 0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 256, 256, 3)  6147        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 256, 256, 3)  0           conv2d_transpose_8[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 54,429,315\n",
      "Trainable params: 54,419,459\n",
      "Non-trainable params: 9,856\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = define_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GAN**\n",
    "\n",
    "Stacking the generator and discriminator to build the actual GAN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model, image_shape):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\td_model.trainable = False\n",
    "\t# define the source image\n",
    "\tin_src = Input(shape=image_shape)\n",
    "\t# connect the source image to the generator input\n",
    "\tgen_out = g_model(in_src)\n",
    "\t# connect the source input and generator output to the discriminator input\n",
    "\tdis_out = d_model([in_src, gen_out])\n",
    "\t# src image as input, generated image and classification output\n",
    "\tmodel = Model(in_src, [dis_out, gen_out])\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 256, 256, 3)  54429315    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 16, 16, 1)    6968257     input_4[0][0]                    \n",
      "                                                                 model_2[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 61,397,572\n",
      "Trainable params: 54,419,459\n",
      "Non-trainable params: 6,978,113\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan = define_gan(generator, discriminator, (256,256,3))\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA HANDLING**\n",
    "\n",
    "We need to load and generate real source (SAR) and target (RGB) images from our dataset. Due to the size, we cannot load it entirely into memory and will have to load the images on demand.\n",
    "\n",
    "The images have to be generalized over four seasons and different geographic locations. Therefore, we build a function to randomly select a season and then randomly select an SAR image and its corresponding optical image pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def get_images(batch_size):\n",
    "    \n",
    "#     base_path = 'munich/'\n",
    "    \n",
    "#     #select season\n",
    "#     files = listdir(base_path)\n",
    "# #     print(files)\n",
    "#     files_len = len(files)\n",
    "# #     print(files_len)\n",
    "#     rint1 = np.random.randint(0, files_len)\n",
    "# #     print(rint1)\n",
    "#     lvl1 = files[rint1]\n",
    "# #     print(lvl1)\n",
    "    \n",
    "#     #select SAR image folder\n",
    "#     files = listdir(base_path + lvl1 + '/s1/')\n",
    "#     files_len = len(files)\n",
    "# #     print(files_len)\n",
    "#     rint2 = np.random.randint(0, files_len)\n",
    "# #     print(rint2)\n",
    "#     lvl2 = files[rint2]\n",
    "# #     print(lvl2)\n",
    "    \n",
    "#     #select SAR image\n",
    "#     s1_path = base_path + lvl1 + '/s1/' + lvl2 + '/'\n",
    "#     files = listdir(s1_path)\n",
    "#     files_len = len(files)\n",
    "# #     print(files_len)\n",
    "#     rint3 = np.random.randint(0, files_len, batch_size)\n",
    "# #     print(rint3)\n",
    "#     files_arr = np.array(files)\n",
    "#     lvl3 = files_arr[rint3]\n",
    "# #     print(lvl3)\n",
    "    \n",
    "#     #select RGB image\n",
    "#     temp2 = lvl2.replace('s1', 's2')\n",
    "#     lvl3_opt = lvl3.tolist()\n",
    "#     temp3 = [sub.replace('_s1_', '_s2_') for sub in lvl3_opt]\n",
    "# #     print(temp2)\n",
    "# #     print(temp3)\n",
    "#     s2_path = base_path + lvl1 + '/s2/' + temp2 + '/'\n",
    "# #     print(s2_path)\n",
    "    \n",
    "#     #load images\n",
    "#     img_sar=[]\n",
    "#     img_opt=[]\n",
    "#     for i in range(batch_size):\n",
    "#         img = load_img(s1_path + lvl3[i])\n",
    "#         img = img_to_array(img)\n",
    "#         img_sar.append(img)\n",
    "#         img = load_img(s2_path + temp3[i])\n",
    "#         img = img_to_array(img)\n",
    "#         img_opt.append(img)\n",
    "        \n",
    "#     img_sar = np.array(img_sar)\n",
    "#     img_opt = np.array(img_opt)\n",
    "#     img_sar = (img_sar - 127.5) / 127.5\n",
    "#     img_opt = (img_opt - 127.5) / 127.5\n",
    "    \n",
    "#     return img_sar, img_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def shuff():\n",
    "    \n",
    "    #select SAR image\n",
    "    s1_path = 'munich/train/s1/'\n",
    "    files = listdir(s1_path)\n",
    "    random.shuffle(files)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper satellite run\n",
    "import numpy as np\n",
    "\n",
    "def get_images(batch_size, files, i):\n",
    "    \n",
    "    sar_img_name = files[i]\n",
    "    \n",
    "    img_sar=[]\n",
    "    img_opt=[]\n",
    "    \n",
    "    s1_path = 'munich/train/s1/'\n",
    "    img = load_img(s1_path + sar_img_name)\n",
    "    img = img_to_array(img)\n",
    "    img_sar.append(img)\n",
    "    \n",
    "    #select RGB image\n",
    "    opt_img_name = sar_img_name.replace('_s1_', '_s2_', 1)\n",
    "#     temp = \"\"\n",
    "#     temp.join(opt_img_name)\n",
    "    \n",
    "    s2_path = 'munich/train/s2/'\n",
    "    img = load_img(s2_path + opt_img_name)\n",
    "#     img = load_img(s2_path + temp)\n",
    "    img = img_to_array(img)\n",
    "    img_opt.append(img)\n",
    "    \n",
    "    img_sar = np.array(img_sar)\n",
    "    img_opt = np.array(img_opt)\n",
    "    img_sar = (img_sar - 127.5) / 127.5\n",
    "    img_opt = (img_opt - 127.5) / 127.5\n",
    "    \n",
    "    return img_sar, img_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # satellite run\n",
    "# import numpy as np\n",
    "\n",
    "# def get_images(batch_size, files):\n",
    "    \n",
    "#     #select SAR image\n",
    "#     s1_path = 'munich/train/s1/'\n",
    "#     files = listdir(s1_path)\n",
    "#     files_len = len(files)\n",
    "# #     print(files_len)\n",
    "#     rint3 = np.random.randint(0, files_len, batch_size)\n",
    "# #     print(rint3)\n",
    "#     files_arr = np.array(files)\n",
    "#     lvl3 = files_arr[rint3]\n",
    "# #     print(lvl3)\n",
    "    \n",
    "#     #select RGB image\n",
    "#     lvl3_opt = lvl3.tolist()\n",
    "#     temp3 = [sub.replace('_s1_', '_s2_') for sub in lvl3_opt]\n",
    "# #     print(temp3)\n",
    "#     s2_path = 'munich/train/s2/'\n",
    "    \n",
    "#     #load images\n",
    "#     img_sar=[]\n",
    "#     img_opt=[]\n",
    "#     for i in range(batch_size):\n",
    "#         img = load_img(s1_path + lvl3[i])\n",
    "#         img = img_to_array(img)\n",
    "#         img_sar.append(img)\n",
    "#         img = load_img(s2_path + temp3[i])\n",
    "#         img = img_to_array(img)\n",
    "#         img_opt.append(img)\n",
    "        \n",
    "#     img_sar = np.array(img_sar)\n",
    "#     img_opt = np.array(img_opt)\n",
    "#     img_sar = (img_sar - 127.5) / 127.5\n",
    "#     img_opt = (img_opt - 127.5) / 127.5\n",
    "    \n",
    "#     return img_sar, img_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dog clean run\n",
    "# import numpy as np\n",
    "\n",
    "# def get_images(batch_size):\n",
    "    \n",
    "#     #select SAR image\n",
    "#     path = 'dog/dog_train/'\n",
    "#     files = listdir(path)\n",
    "#     files_len = len(files)\n",
    "# #     print(files_len)\n",
    "#     rint3 = np.random.randint(0, files_len, batch_size)\n",
    "# #     print(rint3)\n",
    "#     files_arr = np.array(files)\n",
    "#     lvl3 = files_arr[rint3]\n",
    "# #     print(lvl3)\n",
    "    \n",
    "#     #select RGB image\n",
    "#     def rgb2gray(rgb):\n",
    "#         return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "#     img = load_img(path + lvl3[0])\n",
    "#     img = img_to_array(img)\n",
    "#     img = (img - 127.5) / 127.5\n",
    "#     gray = rgb2gray(img)\n",
    "#     gray = np.stack((gray,)*3, axis=-1)\n",
    "# #     plt.imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n",
    "# #     plt.show()\n",
    "    \n",
    "#     #load images\n",
    "#     img_gray=[]\n",
    "#     img_rgb=[]\n",
    "    \n",
    "#     img_gray.append(gray)\n",
    "#     img_rgb.append(img)\n",
    "#     img_gray = np.array(img_gray)\n",
    "#     img_rgb = np.array(img_rgb)\n",
    "    \n",
    "#     return img_gray, img_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dog noisy run\n",
    "# import numpy as np\n",
    "\n",
    "# def get_images(batch_size):\n",
    "    \n",
    "#     #select SAR image\n",
    "#     path = 'dog/dog_train/'\n",
    "#     files = listdir(path)\n",
    "#     files_len = len(files)\n",
    "# #     print(files_len)\n",
    "#     rint3 = np.random.randint(0, files_len, batch_size)\n",
    "# #     print(rint3)\n",
    "#     files_arr = np.array(files)\n",
    "#     lvl3 = files_arr[rint3]\n",
    "# #     print(lvl3)\n",
    "    \n",
    "#     #select RGB image\n",
    "#     def rgb2gray(rgb):\n",
    "#         return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "#     noise = np.random.normal(0, 0.45, (256,256,3))\n",
    "    \n",
    "#     img = load_img(path + lvl3[0])\n",
    "#     img = img_to_array(img)\n",
    "#     img = (img - 127.5) / 127.5\n",
    "#     img2 = img+noise\n",
    "#     gray = rgb2gray(img2)\n",
    "#     gray = np.stack((gray,)*3, axis=-1)\n",
    "# #     plt.imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n",
    "# #     plt.show()\n",
    "    \n",
    "#     #load images\n",
    "#     img_gray=[]\n",
    "#     img_rgb=[]\n",
    "    \n",
    "#     img_gray.append(gray)\n",
    "#     img_rgb.append(img)\n",
    "#     img_gray = np.array(img_gray)\n",
    "#     img_rgb = np.array(img_rgb)\n",
    "    \n",
    "#     return img_gray, img_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src, tar = get_images(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(src[0])\n",
    "# src = (src + 1) / 2\n",
    "# plt.imshow(src[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tar = (tar + 1) / 2\n",
    "# plt.imshow(tar[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(batch_size, patch_shape, files, i):\n",
    "    \n",
    "    #SAR RGB image pair\n",
    "    src, tar = get_images(batch_size, files, i)\n",
    "    #real labels '1'\n",
    "    y = np.ones((batch_size, patch_shape, patch_shape, 1))\n",
    "    \n",
    "    return [src,tar], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(g_model, batch_size, patch_shape):\n",
    "    \n",
    "    #generated RGB image\n",
    "    X = g_model.predict(batch_size)\n",
    "    #fake labels '0'\n",
    "    y = np.zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, index, d_model, g_model, files, n_samples=1):\n",
    "\t# select a sample of input images\n",
    "    [X_realA, X_realB], _ = generate_real_samples(n_samples, 1, files, index)\n",
    "\t# generate a batch of fake samples\n",
    "    X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
    "\t# scale all pixels from [-1,1] to [0,1]\n",
    "    X_realA = (X_realA + 1) / 2.0\n",
    "    X_realB = (X_realB + 1) / 2.0\n",
    "    X_fakeB = (X_fakeB + 1) / 2.0\n",
    "    \n",
    "    score = structural_similarity(X_fakeB[0], X_realB[0], multichannel=True)\n",
    "#     t = \"SSIM score = {}\"\n",
    "#     w = t.format(score)\n",
    "    ssim_score.append(score)\n",
    "    \n",
    "    score2 = normalized_root_mse(X_realB[0], X_fakeB[0])\n",
    "    rmse_score.append(score2)\n",
    "    \n",
    "\t# plot real source images\n",
    "    plt.figure(figsize=(10.1,3.45))\n",
    "#     plt.text(0, 280, w, fontsize=15)\n",
    "    for i in range(n_samples):\n",
    "#         plt.figure(figsize=(3.2,3.2))\n",
    "#         plt.subplot(1, n_samples, 1 + i)\n",
    "        plt.subplot(131)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_realA[i])\n",
    "\t# plot generated target image\n",
    "    for i in range(n_samples):\n",
    "#         plt.figure(figsize=(3.2,3.2))\n",
    "#         plt.subplot(1, n_samples, 1 + n_samples + i)\n",
    "        plt.subplot(132)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_fakeB[i])\n",
    "\t# plot real target image\n",
    "    for i in range(n_samples):\n",
    "#         plt.figure(figsize=(3.2,3.2))\n",
    "#         plt.subplot(1, n_samples, 1 + n_samples*2 + i)\n",
    "        plt.subplot(133)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_realB[i])\n",
    "\t# save plot to file\n",
    "    filename1 = 'plot_%06d.png' % (step+1)\n",
    "    plt.savefig(filename1)\n",
    "    plt.close()\n",
    "\t# save the generator model\n",
    "    filename2 = 'g_model_%06d.h5' % (step+1)\n",
    "    g_model.save(filename2)\n",
    "    # save discriminator\n",
    "    filename3 = 'd_model_%06d.h5' % (step+1)\n",
    "    d_model.save(filename3)\n",
    "    print('>Saved: %s and %s and %s' % (filename1, filename2, filename3))\n",
    "    print('SSIM = ', score)\n",
    "    print('RMSE = ', score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "def train(d_model, g_model, gan_model, n_images, n_epochs=10, n_batch=1):\n",
    "\t# determine the output square shape of the discriminator\n",
    "    n_patch = d_model.output_shape[1]\n",
    "\t# calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(n_images / n_batch)\n",
    "\t# calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "\t# manually enumerate epochs\n",
    "    j=0\n",
    "    for i in range(n_steps):\n",
    "        # shuffle\n",
    "        if(i==0):\n",
    "            files = shuff()\n",
    "        if((i+1) % 12754 == 0):\n",
    "            files = shuff()\n",
    "            j=0\n",
    "\t\t# select a batch of real samples\n",
    "        [X_realA, X_realB], y_real = generate_real_samples(n_batch, n_patch, files, j)\n",
    "\t\t# generate a batch of fake samples\n",
    "        X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "\t\t# update discriminator for real samples\n",
    "        d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "        d1_loss.append(d_loss1)\n",
    "\t\t# update discriminator for generated samples\n",
    "        d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "        d2_loss.append(d_loss2)\n",
    "\t\t# update the generator\n",
    "        g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "        gen_loss.append(g_loss)\n",
    "\t\t# summarize performance\n",
    "        if (i+1) % 3199 == 0:\n",
    "            print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "\t\t# summarize model performance\n",
    "# \t\tif (i+1) % (bat_per_epo * 10) == 0:\n",
    "        if (i+1) % 4251 == 0:\n",
    "            summarize_performance(i, j, d_model, g_model, files)\n",
    "            \n",
    "        j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "D:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "D:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">3199, d1[0.001] d2[0.057] g[29.168]\n",
      ">Saved: plot_004251.png and g_model_004251.h5 and d_model_004251.h5\n",
      "SSIM =  0.2892433236005716\n",
      "RMSE =  0.49399668070229863\n",
      ">6398, d1[0.000] d2[0.056] g[65.240]\n",
      ">Saved: plot_008502.png and g_model_008502.h5 and d_model_008502.h5\n",
      "SSIM =  0.7519972758198432\n",
      "RMSE =  0.7037219487719292\n",
      ">9597, d1[0.008] d2[0.058] g[25.824]\n",
      ">Saved: plot_012753.png and g_model_012753.h5 and d_model_012753.h5\n",
      "SSIM =  0.3665667969747213\n",
      "RMSE =  0.7024156321122679\n",
      ">12796, d1[0.000] d2[0.104] g[35.502]\n",
      ">15995, d1[0.014] d2[0.004] g[9.977]\n",
      ">Saved: plot_017004.png and g_model_017004.h5 and d_model_017004.h5\n",
      "SSIM =  0.20282851808816693\n",
      "RMSE =  0.8926398098328424\n",
      ">19194, d1[0.008] d2[0.007] g[12.655]\n",
      ">Saved: plot_021255.png and g_model_021255.h5 and d_model_021255.h5\n",
      "SSIM =  0.28240211605174165\n",
      "RMSE =  0.5309224614864826\n",
      ">22393, d1[0.001] d2[0.163] g[21.353]\n",
      ">Saved: plot_025506.png and g_model_025506.h5 and d_model_025506.h5\n",
      "SSIM =  0.6198646284323375\n",
      "RMSE =  0.7751220136518995\n",
      ">25592, d1[0.010] d2[0.183] g[27.922]\n",
      ">28791, d1[0.000] d2[0.067] g[22.914]\n",
      ">Saved: plot_029757.png and g_model_029757.h5 and d_model_029757.h5\n",
      "SSIM =  0.2950793217439163\n",
      "RMSE =  0.5821273206515972\n",
      ">31990, d1[0.000] d2[0.035] g[31.199]\n",
      ">Saved: plot_034008.png and g_model_034008.h5 and d_model_034008.h5\n",
      "SSIM =  0.4261091811882803\n",
      "RMSE =  0.4719785601016836\n",
      ">35189, d1[0.018] d2[0.066] g[29.793]\n",
      ">Saved: plot_038259.png and g_model_038259.h5 and d_model_038259.h5\n",
      "SSIM =  0.22622094831268783\n",
      "RMSE =  0.4982072918362782\n",
      ">38388, d1[0.000] d2[0.005] g[25.504]\n",
      ">41587, d1[0.000] d2[0.026] g[46.130]\n",
      ">Saved: plot_042510.png and g_model_042510.h5 and d_model_042510.h5\n",
      "SSIM =  0.3727498238327743\n",
      "RMSE =  0.3763941327623347\n",
      ">44786, d1[0.262] d2[0.184] g[29.305]\n",
      ">Saved: plot_046761.png and g_model_046761.h5 and d_model_046761.h5\n",
      "SSIM =  0.940663950641853\n",
      "RMSE =  0.5218936542212296\n",
      ">47985, d1[0.000] d2[0.002] g[37.343]\n",
      ">Saved: plot_051012.png and g_model_051012.h5 and d_model_051012.h5\n",
      "SSIM =  0.3992947256102615\n",
      "RMSE =  0.2501308513894098\n",
      ">51184, d1[0.059] d2[0.038] g[32.695]\n",
      ">54383, d1[0.452] d2[0.014] g[16.378]\n",
      ">Saved: plot_055263.png and g_model_055263.h5 and d_model_055263.h5\n",
      "SSIM =  0.28147096983830294\n",
      "RMSE =  0.6284180117327902\n",
      ">57582, d1[0.010] d2[0.106] g[30.992]\n",
      ">Saved: plot_059514.png and g_model_059514.h5 and d_model_059514.h5\n",
      "SSIM =  0.3592535044268952\n",
      "RMSE =  0.6643648315833883\n",
      ">60781, d1[0.004] d2[0.051] g[32.724]\n",
      ">Saved: plot_063765.png and g_model_063765.h5 and d_model_063765.h5\n",
      "SSIM =  0.17890281809035116\n",
      "RMSE =  0.5239211989505281\n",
      ">63980, d1[0.954] d2[0.682] g[25.808]\n",
      ">67179, d1[0.532] d2[0.088] g[27.911]\n",
      ">Saved: plot_068016.png and g_model_068016.h5 and d_model_068016.h5\n",
      "SSIM =  0.15417698289830062\n",
      "RMSE =  0.5609464461504534\n",
      ">70378, d1[0.001] d2[0.005] g[22.951]\n",
      ">Saved: plot_072267.png and g_model_072267.h5 and d_model_072267.h5\n",
      "SSIM =  0.30361360384263064\n",
      "RMSE =  0.4708831151497228\n",
      ">73577, d1[0.001] d2[0.008] g[28.790]\n",
      ">Saved: plot_076518.png and g_model_076518.h5 and d_model_076518.h5\n",
      "SSIM =  0.4742281164027147\n",
      "RMSE =  0.3602737084309884\n",
      ">76776, d1[0.004] d2[0.024] g[36.864]\n",
      ">79975, d1[0.004] d2[0.088] g[32.049]\n",
      ">Saved: plot_080769.png and g_model_080769.h5 and d_model_080769.h5\n",
      "SSIM =  0.4213486856231052\n",
      "RMSE =  0.7180246251931585\n",
      ">83174, d1[0.001] d2[0.048] g[32.766]\n",
      ">Saved: plot_085020.png and g_model_085020.h5 and d_model_085020.h5\n",
      "SSIM =  0.42081220640140754\n",
      "RMSE =  0.6638119893962529\n",
      ">86373, d1[0.000] d2[0.019] g[27.714]\n",
      ">Saved: plot_089271.png and g_model_089271.h5 and d_model_089271.h5\n",
      "SSIM =  0.2782634926856839\n",
      "RMSE =  0.6183853982029346\n",
      ">89572, d1[0.002] d2[0.003] g[11.714]\n",
      ">92771, d1[0.706] d2[0.126] g[25.094]\n",
      ">Saved: plot_093522.png and g_model_093522.h5 and d_model_093522.h5\n",
      "SSIM =  0.3055114591782402\n",
      "RMSE =  0.3549475095381307\n",
      ">95970, d1[0.000] d2[0.178] g[6.402]\n",
      ">Saved: plot_097773.png and g_model_097773.h5 and d_model_097773.h5\n",
      "SSIM =  0.3699593031763228\n",
      "RMSE =  0.43877761774979107\n",
      ">99169, d1[0.111] d2[0.202] g[12.577]\n",
      ">Saved: plot_102024.png and g_model_102024.h5 and d_model_102024.h5\n",
      "SSIM =  0.4368153872089658\n",
      "RMSE =  0.5773723410391262\n",
      ">102368, d1[0.538] d2[0.072] g[25.258]\n",
      ">105567, d1[0.316] d2[0.060] g[22.799]\n",
      ">Saved: plot_106275.png and g_model_106275.h5 and d_model_106275.h5\n",
      "SSIM =  0.42951712254701757\n",
      "RMSE =  0.41528359510067364\n",
      ">108766, d1[0.318] d2[0.002] g[27.641]\n",
      ">Saved: plot_110526.png and g_model_110526.h5 and d_model_110526.h5\n",
      "SSIM =  0.31616891097851835\n",
      "RMSE =  0.5164708857161807\n",
      ">111965, d1[0.004] d2[0.045] g[28.886]\n",
      ">Saved: plot_114777.png and g_model_114777.h5 and d_model_114777.h5\n",
      "SSIM =  0.36262030634150744\n",
      "RMSE =  0.4695346353660389\n",
      ">115164, d1[0.069] d2[0.001] g[36.316]\n",
      ">118363, d1[0.280] d2[0.003] g[25.163]\n",
      ">Saved: plot_119028.png and g_model_119028.h5 and d_model_119028.h5\n",
      "SSIM =  0.8643167816614531\n",
      "RMSE =  0.8933203260259965\n",
      ">121562, d1[0.003] d2[0.007] g[32.603]\n",
      ">Saved: plot_123279.png and g_model_123279.h5 and d_model_123279.h5\n",
      "SSIM =  0.3635752236063197\n",
      "RMSE =  0.3254508878965696\n",
      ">124761, d1[0.039] d2[0.459] g[28.672]\n",
      ">Saved: plot_127530.png and g_model_127530.h5 and d_model_127530.h5\n",
      "SSIM =  0.4999085601481405\n",
      "RMSE =  0.35524499553980515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#input shape\n",
    "image_shape = (256, 256, 3)\n",
    "\n",
    "#number of images\n",
    "n_images = 12754\n",
    "\n",
    "ssim_score = []\n",
    "rmse_score = []\n",
    "d1_loss = []\n",
    "d2_loss = []\n",
    "gen_loss = []\n",
    "\n",
    "# define the models\n",
    "d_model = define_discriminator(image_shape)\n",
    "g_model = define_generator(image_shape)\n",
    "# define the composite model\n",
    "gan_model = define_gan(g_model, d_model, image_shape)\n",
    "\n",
    "# train model\n",
    "train(d_model, g_model, gan_model, n_images)\n",
    "\n",
    "plt.plot(ssim_score)\n",
    "plt.ylabel('SSIM')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ssim_score[5])\n",
    "# plt.plot(ssim_score)\n",
    "# plt.ylabel('SSIM')\n",
    "# plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
